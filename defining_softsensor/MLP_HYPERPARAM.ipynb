{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes: train = (17389, 10), y_train = (17389, 1), test = (8566, 10), y_teste = (8566, 1)\n"
     ]
    }
   ],
   "source": [
    "main_path = '../overfitting/setTraining/select_noOhe/select_softsensor/10var/'\n",
    "train = np.load(main_path+'train.npy')\n",
    "test = np.load(main_path+'test.npy')\n",
    "y_train = np.load(main_path+'y_train.npy')\n",
    "y_test = np.load(main_path+'y_test.npy')\n",
    "print('shapes: train = {}, y_train = {}, test = {}, y_teste = {}'.format(train.shape,y_train.shape,test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardscaler x data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_x = StandardScaler()\n",
    "X_trainScaled = sc_x.fit_transform(train)\n",
    "X_testScaled = sc_x.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17389,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "y = np.ravel(y_train)\n",
    "y_test = np.ravel(y_test)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using best hyperparameters\n",
    "Best parameters found:\n",
    " {'activation': 'relu', 'alpha': 0.0001, 'batch_size': 50, 'hidden_layer_sizes': (256, 128, 64, 32), 'learning_rate': 'adaptive', 'power_t': 0.5, 'solver': 'sgd'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7950035022180715\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver=\"sgd\",learning_rate=\"adaptive\",hidden_layer_sizes=(256, 128, 64, 32),\n",
    "batch_size=50,alpha=0.0001,activation=\"relu\",max_iter=500,random_state=1).fit(X_trainScaled, y)\n",
    "y_pred=clf.predict(X_testScaled)\n",
    "print(clf.score(X_testScaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multilabel classification\n",
    "F1 score reaches its best value at 1 and worst score at 0\n",
    "\n",
    "F1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "In the multi-class and multi-label case, this is the average of the F1 score of each class with weighting depending on the average parameter\n",
    "\n",
    "### This parameter is required for multiclass/multilabel targets. If None, the scores for each class are returned.\n",
    "\n",
    "# multilabel classification\n",
    "F1 score reaches its best value at 1 and worst score at 0\n",
    "\n",
    "F1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "In the multi-class and multi-label case, this is the average of the F1 score of each class with weighting depending on the average parameter\n",
    "\n",
    "### This parameter is required for multiclass/multilabel targets. If None, the scores for each class are returned.\n",
    "average{‘micro’, ‘macro’, ‘samples’,’weighted’, ‘binary’} or None, default=’binary’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7977077661257672\n",
      "0.7950035022180715\n",
      "0.7974963176917176\n",
      "[0.78812861 0.76046213 0.7162819  0.85317221 0.87049399]\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_test, y_pred, average='macro'))\n",
    "print(f1_score(y_test, y_pred, average='micro'))\n",
    "print(f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "# return for each class\n",
    "print(f1_score(y_test, y_pred, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7950035022180715"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65034014, 0.61350456, 0.55797444, 0.74394099, 0.77068558])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "jaccard_score(y_test, y_pred, average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### roc_auc_score\n",
    "Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores.\n",
    "\n",
    "**multi_class{‘raise’, ‘ovr’, ‘ovo’}, default=’raise’**\n",
    "\n",
    "Stands for One-vs-rest. Computes the AUC of each class against the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9614198768012155"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = clf.predict_proba(X_testScaled)\n",
    "roc_auc_score(y_test, y_pred_proba, average='macro', multi_class='ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1434,  268,   41,   10,    0],\n",
       "       [ 165, 1481,   48,   13,    0],\n",
       "       [ 188,  302, 1179,   30,    7],\n",
       "       [  41,   74,  188, 1412,   17],\n",
       "       [  58,   63,  130,  113, 1304]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
